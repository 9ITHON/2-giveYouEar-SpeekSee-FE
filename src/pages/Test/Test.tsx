import styled from 'styled-components';
import ScriptSection from './components/ScriptSection';
import CloseButtonImg from '../../assets/png/daily-script-button.png';
import CloseButton from './components/CloseButton';
import Divider from './components/Divider';
import ActivityButtons from './components/ActivityButtons';
import { useCallback, useEffect, useRef, useState } from 'react';
import Modal from './components/Modal';
import { Outlet, useLocation, useNavigate } from 'react-router-dom';
import ProgressBar from './components/ProgressBar';
import PracticeDescription from './components/PracticeDescription';
import Result from './components/Result';
import type { TestContext } from './types/TestContext';
import getLevelTestScripts from '../../apis/getLevelTestScripts';
import BlueText from '../Script/components/BlueText';
import { letsCheckSpokenWords } from '../Script/utils/letsCheckSpokenWords';
import type { MappedResult } from '../Script/types/MappedResult';
import RedText from '../Script/components/RedText';
import SkyblueText from '../Script/components/SkyblueText';

const TestStyle = styled.div`
  height: 100%;
  background-color: #a2caff;
  position: relative;
`;

const Test = () => {
  // ëŒ€ë³¸ ê´€ë ¨
  /** introStatus ì†Œê°œ
   * --------------
   * -1: ì—°ìŠµ ì‹œì‘. ëŒ€ë³¸ì´ ë Œë”ë§
   * 0~2: ëŒ€ë³¸ì´ ë Œë”ë§ ë˜ì§€ ì•ŠìŒ. ì„¤ëª…ì„ ë“¤ìœ¼ë©´ì„œ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ëŠ” ë²„íŠ¼ í´ë¦­ í™”ë©´ì„ ë Œë”ë§
   * 0: "ì•ˆë…•í•˜ì„¸ìš”!" í™˜ì˜ ì¸ì‚¬
   * 1: "ì‹œì‘í•˜ê¸° ì „, ì—¬ëŸ¬ë¶„ì´ ì–´ëŠ ë¶€ë¶„ì—ì„œ ì–´ë ¤ì›Œí•˜ëŠ”ì§€ ì•Œì•„ë³´ê³ ì ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤!"
   * 2: "í…ŒìŠ¤íŠ¸ í•  ìˆ˜ ìˆë„ë¡ ì¡°ìš©í•œ ê³µê°„ì—ì„œ ì‹œì‘í•´ì£¼ì‹œê³  ì¤€ë¹„ê°€ ë˜ì—ˆë‹¤ë©´ ì•„ë˜ ë…¹ìŒí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!"
   */
  const [introStatus, setIntroStatus] = useState<number>(0);
  /** status ì†Œê°œ
   * --------------
   * 0: ë…¹ìŒ ì „
   * 1: ë…¹ìŒ ì¤‘
   * 2: ë…¹ìŒ ì¢…ë£Œ/ì™„ë£Œ
   * 3: ë¶„ì„ ì¤‘
   * 4: ë‹¤ìŒ í™”ë©´ìœ¼ë¡œ ì´ë™ í…ìŠ¤íŠ¸
   * 5: ë‚˜ê°€ê¸° ë²„íŠ¼ í™œì„±í™”
   */
  const [status, setStatus] = useState<number>(0);
  /**
   * outroStatus ì†Œê°œ
   * --------------
   * -1: ì—°ìŠµ ì‹œì‘, ì—°ìŠµ ì¤‘
   * 0~2: ì—°ìŠµ ì™„ë£Œ
   * 0: ë¶„ì„ ì¤‘
   * 1: ê²°ê³¼ í™•ì¸
   * 2: ë‚˜ê°€ê¸° ë²„íŠ¼ í™œì„±í™”
   */
  const [outroStatus, setOutroStatus] = useState<number>(-1);
  const [isClosed, setIsClosed] = useState<boolean>(false);
  const [step, setStep] = useState<number>(1); // í•™ìŠµ ëŒ€ë³¸ ë‹¨ê³„
  const [scripts, setScripts] = useState<React.ReactNode[]>([]);
  const [curScript, setCurScript] = useState<React.ReactElement[]>([]);
  const curScriptRef = useRef<React.ReactElement[]>([]);
  const expectedWordsRef = useRef<string[]>([]); // ì˜ˆìƒë˜ëŠ” ë‹¨ì–´ë“¤ì„ <SkyblueText> ì»´í¬ë„ŒíŠ¸ë¡œ ê°ì‹¸ì„œ ê´€ë¦¬
  const wordsLengthRef = useRef<number>(0);
  const checkIdxRef = useRef<number>(0);
  const totalCurScriptLength = useRef<number>(0);
  const [accuracies, setAccuracies] = useState<number[]>([0, 0, 0]);
  const [totalCounts, setTotalCounts] = useState<number[]>([0, 0, 0]); // í•™ìŠµ ì§„í–‰ - ì´ ë‹¨ì–´ ê°œìˆ˜
  const [correctCounts, setCorrectCounts] = useState<number[]>([0, 0, 0]); // í•™ìŠµ ì§„í–‰ - ë§ì€ ë‹¨ì–´ ê°œìˆ˜
  const location = useLocation();
  const paths = location.pathname.split('/');
  const scriptid = Number(paths[paths.length - 1]);
  const memberid = 1;
  const navigate = useNavigate();

  // ì˜¤ë””ì˜¤ ë° ì›¹ì†Œì¼“ ê´€ë ¨
  const [isTalking, setIsTalking] = useState(false);
  const webSocket = useRef<WebSocket>(null);
  const stream = useRef<MediaStream>(null);
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioContext = useRef<AudioContext | null>(null);
  const processor = useRef<AudioWorkletNode | null>(null);

  // 1) í•œ ë²ˆë§Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
  useEffect(() => {
    (async () => {
      const data = await getLevelTestScripts()
        .then(res => (res.data.success ? res.data.data.content : null))
        .catch(err => {
          console.error(err);
          return null;
        });

      if (!data || data.length === 0) {
        console.warn('ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.');
        return;
      }

      // scripts ìƒíƒœì— "ë¬¸ìì—´ ë°°ì—´"ë¡œ ì €ì¥
      setScripts(data.map((item: any) => item.content as string));
    })();
  }, []);

  // 2) scripts ë˜ëŠ” stepì´ ë°”ë€” ë•Œë§ˆë‹¤ curScript/expectedWords ê³„ì‚°
  useEffect(() => {
    // ì•ˆì „í•˜ê²Œ ê¸¸ì´ í™•ì¸
    if (scripts.length === 0 || step < 1 || step > scripts.length) {
      return;
    }

    const text = scripts[step - 1]; // ë°˜ë“œì‹œ string
    const words = text.split(' '); // ["ì˜¤ëŠ˜ì˜", "ë‚ ì”¨ëŠ”", "..."]

    expectedWordsRef.current = words;
    totalCurScriptLength.current = words.length;
    checkIdxRef.current = 0;

    setCurScript(words.map((w: string, i: number) => <SkyblueText key={i}>{w}</SkyblueText>));
  }, [scripts, step]);

  useEffect(() => {
    curScriptRef.current = curScript;
  }, [curScript]);

  const handleRecordBtn = useCallback(() => {
    if (introStatus !== -1) {
      setIntroStatus(-1);
      return;
    }
    if (status === 0) {
      startRecognizingVoice();
    } else if (status === 1) {
      console.log('ë…¹ìŒ ì¢…ë£Œ ì‹œë„!');
      setStatus(2);
      endRecognizingVoice();
      webSocket.current?.send(JSON.stringify({ type: 'END_SENTENCE' }));
      setTimeout(() => {
        setStep(prev => {
          if (prev === 2) {
            setOutroStatus(0);
            navigate('/test/done');
            return 1;
          } else {
            setStatus(0);
            navigate(`/test/${prev + 1}`);
            return prev + 1;
          }
        });
      }, 3000);
    }
  }, [status]);

  const endWebSocket = useCallback(() => {
    if (webSocket.current) {
      webSocket.current.close();
      webSocket.current = null;
    }
  }, []);

  const endRecognizingVoice = useCallback(() => {
    if (stream.current) {
      stream.current.getTracks().forEach(track => track.stop());
      stream.current = null;
    }
    if (processor.current) {
      processor.current.disconnect();
      processor.current = null;
    }
    if (audioContext.current) {
      audioContext.current.close();
      audioContext.current = null;
    }
    if (mediaRecorder.current) {
      mediaRecorder.current.stop();
      mediaRecorder.current = null;
    }
  }, []);

  const startRecognizingVoice = useCallback(() => {
    const start = async () => {
      endRecognizingVoice();
      webSocket.current = new WebSocket('ws://54.180.116.11:8080/ws/stt');

      webSocket.current.onopen = () => {
        console.log(webSocket.current);
        webSocket.current?.send(
          JSON.stringify({
            type: 'AUTH',
            token: `Bearer ${import.meta.env.VITE_ACCESS_TOKEN}`,
            memberId: memberid,
            scriptId: scriptid,
            mode: 'LEVEL_TEST',
          }),
        );
        setTimeout(async () => {
          try {
            const sampleRate = 16000;
            const chunkRate = 100;
            stream.current = await navigator.mediaDevices.getUserMedia({
              audio: {
                sampleRate: sampleRate,
                channelCount: 1,
              },
            });
            mediaRecorder.current = new MediaRecorder(stream.current);
            audioContext.current = new window.AudioContext({
              sampleRate: sampleRate,
            });
            const source = audioContext.current.createMediaStreamSource(stream.current);
            await audioContext.current.audioWorklet.addModule('/linear16-processor.js');

            processor.current = new AudioWorkletNode(audioContext.current, 'linear16-processor');
            processor.current.port.onmessage = event => {
              if (webSocket.current?.readyState === WebSocket.OPEN) {
                webSocket.current.send(event.data);
              }
            };

            const analyser = audioContext.current.createAnalyser();
            analyser.fftSize = 256;
            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            source.connect(processor.current);
            processor.current.connect(audioContext.current.destination);
            source.connect(analyser);

            const detectTalking = () => {
              analyser.getByteFrequencyData(dataArray);
              const avgVolume = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
              if (avgVolume >= 20) {
                setIsTalking(true);
              } else {
                setIsTalking(false);
              }
              requestAnimationFrame(detectTalking);
            };

            detectTalking();

            mediaRecorder.current.onstop = () => {
              if (processor.current && audioContext.current) {
                source.disconnect(processor.current);
                processor.current.disconnect(audioContext.current.destination);
              }
            };

            mediaRecorder.current.start(chunkRate);
            setStatus(1);
          } catch (error) {
            console.error(error);
            endRecognizingVoice();
            endWebSocket();
            setStatus(0);
          }
        }, 300);
      };

      webSocket.current.onmessage = e => {
        try {
          const data = JSON.parse(e.data);
          console.log(data);
          if (data.type === 'AUTH_OK') {
            console.log('ğŸ” ì¸ì¦ ì„±ê³µ');
          } else if (data.type === 'ERROR') {
            console.error(`âŒ ì˜¤ë¥˜: ${data.message}`);
            endRecognizingVoice();
            endWebSocket();
            console.log('190ë²ˆì§¸ ì¤„ì—ì„œ closeê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤!');
          } else if (data.type === 'INTERIM_FINAL') {
            console.log('ğŸ’¡ ìµœì¢… ì¸ì‹ ê²°ê³¼:', data.transcript);
            checkIdxRef.current += wordsLengthRef.current;
            wordsLengthRef.current = 0;
          } else if (data.type === 'INTERIM') {
            console.log('ğŸ“© ì¸ì‹ ê²°ê³¼:', data.transcript);
            const curWords = [...curScriptRef.current];
            const subwords = data.transcript.split(' ');
            if (subwords.length > wordsLengthRef.current) {
              for (
                let i = wordsLengthRef.current + checkIdxRef.current;
                i < 39 && i < subwords.length + checkIdxRef.current;
                i++
              ) {
                curWords[i] = <BlueText key={i}>{expectedWordsRef.current[i]}</BlueText>;
              }
              curScriptRef.current = curWords;
              setCurScript(curScriptRef.current);
              wordsLengthRef.current = subwords.length;
            }
          } else if (data.type === 'FINAL_FLUSH') {
            if (webSocket.current && webSocket.current.readyState === webSocket.current.OPEN) {
              console.log('ë…¹ìŒ ì¢…ë£Œ! ê²°ê³¼ ì „ì†¡ ì¤‘...');
              setTimeout(() => {
                webSocket.current?.close();
                webSocket.current = null;
                endWebSocket();
              }, 2000);
            }
            setTimeout(() => {
              const words = letsCheckSpokenWords(data.words, expectedWordsRef.current);
              let correctWordsCount = 0;
              setCurScript(
                words.map((word: MappedResult, index: number) => {
                  if (word.correct) {
                    correctWordsCount += 1;
                    return <BlueText key={index}>{word.word}</BlueText>;
                  }
                  return <RedText key={index}>{word.expected}</RedText>;
                }),
              );
              const curAccuracies = [...accuracies];
              const curCorrectCounts = [...correctCounts];
              const curTotalCounts = [...totalCounts];
              curAccuracies[step - 1] = Math.floor((correctWordsCount / words.length) * 1000) / 10;
              curCorrectCounts[step - 1] = correctWordsCount;
              curTotalCounts[step - 1] = words.length;
              setAccuracies(curAccuracies);
              setCorrectCounts(curCorrectCounts);
              setTotalCounts(curTotalCounts);
              if (step === scripts.length) {
                setOutroStatus(0);
                setStatus(4);
              }
            }, 3000);
            endRecognizingVoice();
            endWebSocket();
            console.log('206ë²ˆì§¸ ì¤„ì—ì„œ closeê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤!');
          } else {
            console.log('sibal');
          }
        } catch (err) {
          console.warn('âŒ ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', err);
          endRecognizingVoice();
          endWebSocket();
          console.log('215ë²ˆì§¸ ì¤„ì—ì„œ closeê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤!');
        }
      };

      webSocket.current.onerror = e => {
        console.error('ğŸš¨ WebSocket ì—ëŸ¬:', e);
        endRecognizingVoice();
        endWebSocket();
      };

      webSocket.current.onclose = () => {
        console.log('ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
        endRecognizingVoice();
        endWebSocket();
      };
    };
    start();
  }, []);
  const contextValue: TestContext = {
    status,
    introStatus,
    setIntroStatus,
    script: scripts[step - 1],
    step,
  };
  return (
    <TestStyle>
      {isClosed && <Modal setIsClosed={setIsClosed} />}
      <CloseButton
        onClick={() => {
          setIsClosed(prev => !prev);
        }}
      >
        <img src={CloseButtonImg} alt="daily-scripts-page-close-button" width="18" height="18" />
      </CloseButton>
      <ScriptSection>
        <ProgressBar step={step} totalStep={scripts.length} />
        <PracticeDescription introStatus={introStatus} status={status} />
        <Outlet context={contextValue} />
        {status === 4 && (
          <Result accuracies={accuracies} totalCounts={totalCounts} correctCounts={correctCounts} />
        )}
      </ScriptSection>
      <Divider />
      <ActivityButtons
        status={status}
        introStatus={introStatus}
        isTalking={isTalking}
        handleRecordBtn={handleRecordBtn}
      />
    </TestStyle>
  );
};

export default Test;
